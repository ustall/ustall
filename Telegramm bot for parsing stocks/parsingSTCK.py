import requests
from datetime import datetime
from bs4 import BeautifulSoup as BS
import re


def datatime():
    now = str(datetime.now().date()) + " " + str(datetime.now().hour) + ":" + str(datetime.now().minute)
    dataInfo = ""
    dataInfo = dataInfo + "\nĞĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ñ ÑĞ°Ğ¹Ñ‚Ğ° finance.yahoo.com Ğ½Ğ° " + now + " Ğ¿Ğ¾ ĞœĞ¡Ğš "
    return dataInfo


def datatime_ru():
    now = str(datetime.now().date()) + " " + str(datetime.now().hour) + ":" + str(datetime.now().minute)
    dataInfo = ""
    dataInfo = dataInfo + "\nĞĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ñ ÑĞ°Ğ¹Ñ‚Ğ° smart-lab.ru Ğ½Ğ° " + now + " Ğ¿Ğ¾ ĞœĞ¡Ğš "
    return dataInfo


def parse_usd_up():
    response = requests.get('https://finance.yahoo.com/screener/predefined/day_gainers')
    soup = BS(response.content, 'html.parser')
    dt_str = ""
    MainData = soup.find_all("tr", class_="simpTblRow Bgc($hoverBgColor):h BdB Bdbc($seperatorColor) Bdbc("
                                          "$tableBorderBlue):h H(32px) Bgc($lv2BgColor)")
    for i in range(5):
        sub_list = MainData[i]
        dt_str += "\n" + str(i + 1) + ")   ğŸ’¼ ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ - " + sub_list.find('td', {'aria-label': 'Name'}).text
        dt_str += "\nğŸ·ï¸Ğ¢Ğ¸ĞºĞµÑ€ $" + sub_list.find('a', {'data-test': 'quoteLink'}).text
        dt_str += "\nğŸ“ˆĞ Ğ¾ÑÑ‚ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚Ğ°Ñ… " + sub_list.find('td', {'aria-label': '% Change'}).text
        dt_str += "\nğŸ’²Ğ¦ĞµĞ½Ğ° = " + sub_list.find('td', {'aria-label': 'Price (Intraday)'}).text + " $USD\n"
    dt_str += datatime()
    return dt_str


def parse_usd_dwn():
    response = requests.get('https://finance.yahoo.com/screener/predefined/day_losers')
    soup = BS(response.content, 'html.parser')
    dt_str = ""
    MainData = soup.find_all("tr", class_="simpTblRow Bgc($hoverBgColor):h BdB Bdbc($seperatorColor) Bdbc("
                                          "$tableBorderBlue):h H(32px) Bgc($lv2BgColor)")
    for i in range(5):
        sub_list = MainData[i]
        dt_str += "\n" + str(i + 1) + ")   ğŸ’¼ ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ - " + sub_list.find('td', {'aria-label': 'Name'}).text
        dt_str += "\nğŸ·ï¸Ğ¢Ğ¸ĞºĞµÑ€ $" + sub_list.find('a', {'data-test': 'quoteLink'}).text
        dt_str += "\nğŸ“ˆĞŸĞ°Ğ´ĞµĞ½Ğ¸Ğµ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚Ğ°Ñ… " + sub_list.find('td', {'aria-label': '% Change'}).text
        dt_str += "\nğŸ’²Ğ¦ĞµĞ½Ğ° = " + sub_list.find('td', {'aria-label': 'Price (Intraday)'}).text + " $USD\n"
    dt_str += datatime()
    return dt_str


def parse_usd_top():
    response = requests.get('https://finance.yahoo.com/screener/predefined/most_actives')
    soup = BS(response.content, 'html.parser')
    dt_str = ""
    MainData = soup.find_all("tr", class_="simpTblRow Bgc($hoverBgColor):h BdB Bdbc($seperatorColor) Bdbc("
                                          "$tableBorderBlue):h H(32px) Bgc($lv2BgColor)")
    for i in range(10):
        sub_list = MainData[i]
        dt_str += "\n" + str(i + 1) + ")  ğŸ’¼ ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ - " + sub_list.find('td', {'aria-label': 'Name'}).text
        dt_str += "\nğŸ·ï¸ Ğ¢Ğ¸ĞºĞµÑ€ $" + sub_list.find('a', {'data-test': 'quoteLink'}).text
        dt_str += "\nğŸ“ˆ Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚Ğ°Ñ… " + sub_list.find('td', {'aria-label': '% Change'}).text
        dt_str += "\nğŸ’²Ğ¦ĞµĞ½Ğ° = " + sub_list.find('td', {'aria-label': 'Price (Intraday)'}).text + " $USD\n"
    dt_str += datatime()
    return dt_str


def parse_rub_top():
    response = requests.get('https://smart-lab.ru/q/shares/')
    soup = BS(response.content, 'html.parser')
    dt_str = ""
    MainData = soup.find_all("tr")
    for i in range(11):
        sub_list = MainData[i + 1]
        dt_str += "\n" + str(i + 1) + ") ğŸ’¼ ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ - " + sub_list.find('a').text
        sub_list2 = sub_list.find_all("td")
        dt_str += "\nğŸ·ï¸ Ğ¢Ğ¸ĞºĞµÑ€ $" + sub_list2[3].text
        dt_str += "\nğŸ“ˆ Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚Ğ°Ñ…" + re.sub("^\s+|\n|\r|\s+$", '', sub_list2[8].text)
        dt_str += "\nğŸ’²Ğ¦ĞµĞ½Ğ° " + sub_list2[7].text + " â‚½RUB\n"
    dt_str += datatime_ru()
    return dt_str


def parse_rub_up():
    response = requests.get('https://smart-lab.ru/q/shares/order_by_last_to_prev_price/desc/')
    soup = BS(response.content, 'html.parser')
    dt_str = ""
    MainData = soup.find_all("tr")
    for i in range(5):
        sub_list = MainData[i + 2]
        dt_str += "\n" + str(i + 1) + ") ğŸ’¼ ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ - " + sub_list.find('a').text
        sub_list2 = sub_list.find_all("td")
        dt_str += "\nğŸ·ï¸ Ğ¢Ğ¸ĞºĞµÑ€ $" + sub_list2[3].text
        dt_str += "\nğŸ“ˆ Ğ Ğ¾ÑÑ‚ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚Ğ°Ñ…" + re.sub("^\s+|\n|\r|\s+$", '', sub_list2[8].text)
        dt_str += "\nğŸ’²Ğ¦ĞµĞ½Ğ° " + sub_list2[7].text + " â‚½RUB\n"
    dt_str += datatime_ru()
    return dt_str


def parse_rub_down():
    response = requests.get('https://smart-lab.ru/q/shares/order_by_last_to_prev_price/asc/')
    soup = BS(response.content, 'html.parser')
    dt_str = ""
    MainData = soup.find_all("tr")
    for i in range(5):
        sub_list = MainData[i + 2]
        dt_str += "\n" + str(i + 1) + ") ğŸ’¼ ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ - " + sub_list.find('a').text
        sub_list2 = sub_list.find_all("td")
        dt_str += "\nğŸ·ï¸ Ğ¢Ğ¸ĞºĞµÑ€ $" + sub_list2[3].text
        dt_str += "\nğŸ“ˆ ĞŸĞ°Ğ´ĞµĞ½Ğ¸Ğµ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚Ğ°Ñ…" + re.sub("^\s+|\n|\r|\s+$", '', sub_list2[8].text)
        dt_str += "\nğŸ’²Ğ¦ĞµĞ½Ğ° " + sub_list2[7].text + " â‚½RUB\n"
    dt_str += datatime_ru()
    return dt_str


if __name__ == '__main__':
    print(parse_rub_up())
